<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://giangson19.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://giangson19.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-22T07:39:44+00:00</updated><id>https://giangson19.github.io/feed.xml</id><title type="html">blank</title><subtitle>Personal academic portoflio. </subtitle><entry><title type="html">969 days in the life of a data analyst</title><link href="https://giangson19.github.io/blog/969-days-in-the-life-of-a-data-analyst/" rel="alternate" type="text/html" title="969 days in the life of a data analyst"/><published>2025-04-10T00:00:00+00:00</published><updated>2025-04-10T00:00:00+00:00</updated><id>https://giangson19.github.io/blog/969-days-in-the-life-of-a-data-analyst</id><content type="html" xml:base="https://giangson19.github.io/blog/969-days-in-the-life-of-a-data-analyst/"><![CDATA[<p style="text-align: justify;">Before my Master's, I worked as a&nbsp;<strong>Data Analyst</strong> at <a href="https://onemount.com/" target="_blank" rel="noopener"><strong>One Mount Group</strong></a> (leading tech ecosystem with 3 digital products) from Oct 2021 until May 2024. I was recruited by the Talent Incubation Program (Fresh Geeks) and was mentored by <a href="https://www.linkedin.com/in/vuhoangt/">Vu Hoang</a> (now PhD Student in Information Systems, CMU). I started in the <a href="https://vinid.net/">VinID</a> analytics team (lifestyle &amp; fintech app, 13+ million users) and then worked simultaneously in the&nbsp;<a href="https://onehousing.vn/">OneHousing</a> team (proptech, 1-2 million monthly traffic) from mid 2022.</p> <center> <img style="width:50%" src="https://media.licdn.com/dms/image/v2/D5622AQHrgyBnsvx2Pw/feedshare-shrink_1280/feedshare-shrink_1280/0/1717167494624?e=1748476800&amp;v=beta&amp;t=Oo5E7MI1usjCr7oPibWOcfJr0_eAI-Y2ZRvPxWUP0sA"/> </center> <p style="text-align: justify;">My work at One Mount revolved around three pillars: <strong>Business Intelligence</strong> (analytics &amp; reporting), <strong>Data Engineering&nbsp;</strong>and<strong> Machine Learning</strong>. Some tasks were unconventional for an analyst, due to my tendency to gravitate towards more technical and experimental work.</p> <p style="text-align: justify;">Below is an non-exhaustive list of the projects I contributed to along with what I did and what I learnt. I do my best to describe them without revealing sensitive information.</p> <p style="padding-left: 40px; text-align: justify;"><strong>Machine Learning</strong>:</p> <details style="padding-left: 40px;"> <summary><em>(2023) VinID Customer Income Prediction (xgboost)</em></summary> I leveraged our existing features store and experimented with XGBoost to classify customer into 3 income ranges (multi-class classification). The project was unsuccessful due to the lack of meaningful predictors, and time mismatch between labels (collected in 2019) and features (no data from 2019, so we used data from 2020-2022 as proxy).</details> <details style="padding-left: 40px;"> <summary><em>(2023) VinID Voucher attributes (decision tree)</em></summary> I fitted a decision tree on vouchers with high/low redemption rate and interpreted the tree to identify the most important attributes of a voucher that would affect its redemption.</details> <details style="padding-left: 40px;"> <summary><em>(2022) Onehousing x VinID Lookalike customers (catboost)</em></summary> I used a catboost model (binary classification) to identify customers that are similar to existing homebuyers, using features store from VinID. I also engineered some new features that was considered of high importance by the model. I learnt how to formalize business questions into data science problems, to diagnose the model's performance, and to automate steps in the machine learning pipelines to facilitate experimentations. This was also my first exposure to the imbalanced learning problem.</details> <details style="padding-left: 40px;"> <summary><em>(2022) VinID Notification Interaction Prediction (catboost)</em></summary> I used a catboost model to identify customers that are likely to interact with a notification. I also engineered some new features. I learnt how to quickly experiment with different model configurations and feature combinations.</details> <details style="padding-left: 40px;"> <summary><em>(2021) VinID Winmart holiday sales prediction (Prophet)</em></summary> I attempted to predict 2022 Tet holiday item-level sales using the Facebook's Prophet library. The model was unsuccessful due to the lack of representative data, as the 2021 data was heavily skewed by the COVID-19 pandemic. This is my first exposure to predictive analytics and time series problems.</details> <p style="padding-left: 40px; text-align: justify;">&nbsp;</p> <p style="padding-left: 40px; text-align: justify;"><strong>Analytics Projects:</strong></p> <details style="padding-left: 40px;"> <summary><em>(2024) Onehousing Customer Journey Analysis</em></summary> We analyzed the common paths (each step is a feature on the site) customers took after entering our website. We learnt that there was not a clear common path due to a lack of internal links between pages.</details> <details style="padding-left: 40px;"> <summary><em>(2023) Onehousing Non-Listing Content Problem</em></summary> We explored the behavior of organic users (i.e, they found our website via Google) and attempted to find patterns that would identify high-likelihood house buyers. I led the initiative along with two other analysts, proposed ideas to track the behavior, proposed a metric that corresponded with high retention, and did the early exploratory analysis. I also informed the data tracking template and data warehouse design for this problem.</details> <details style="padding-left: 40px;"> <summary><em>(2022) Onehousing x VinID Growth Project</em></summary> We linked customer attributes (demographic, socio-economic, spatial data, etc.) to real estate purchasing behavior to identify key customer segments. My team and I provided early insights on customer profile informing acquisition strategy, I proposed data collection and experimentation method, and built a dashboard to monitor key project metrics.</details> <p style="padding-left: 40px; text-align: justify;">&nbsp;</p> <p style="padding-left: 40px; text-align: justify;"><strong>Data Engineering</strong>:</p> <details style="padding-left: 40px;"> <summary><em>(2023) Onehousing Alert Engine (Python, SQL, dbt, Airflow)</em></summary> I designed and developed a system that automatically detects mismatched records between two data sources and sends alerts to the Operations and Sales teams. This helps significantly reduce the time spent on data reconciliation. I learnt to thinking in systems.</details> <details style="padding-left: 40px;"> <summary><em>(2023) Onehousing CEO Daily Update Bot (Python, SQL, dbt, Airflow)</em></summary> I built a script that sends daily Slack updates to the CEO about real estate deals in OneHousing. I learnt how to work with the Slack and Tableau API, as well as PyODBC.</details> <details style="padding-left: 40px;"> <summary><em>(2023) VinID Voucher, Notification, Ticketing Datamart (dimensional datawarehouse design)</em></summary> I designed and built dimensional datamarts for the various VinID business functions, which contain data about vouchers, app notification, and ticketing. I learnt a lot about dimensional modelling and data warehouse design in the process.</details> <details style="padding-left: 40px;"> <summary><em>(2022) VinID Data Platform Migration (BigQuery -&gt; Dremio)</em></summary> We changed our data platform and query engine from Bigquery to Dremio. I re-wrote and optimized SQL queries and data pipelines to fit the new platform. I learnt ELT best practices, most of my subsequent pipelines adhered to <a href="https://docs.getdbt.com/best-practices/how-we-style/0-how-we-style-our-dbt-projects" target="_blank" rel="noopener">dbt style guide</a>.</details> <details style="padding-left: 40px;"> <summary><em>All dashboards/reports/models data pipelines (SQL, dbt, Airflow)</em></summary> I built data processing pipelines (partially or entirely) for all projects that I was involved in. I learnt how write readable code and manage my code with Git.</details> <p style="padding-left: 40px; text-align: justify;">&nbsp;</p> <p style="padding-left: 40px; text-align: justify;"><strong>Dashboards:</strong></p> <details style="padding-left: 40px;"> <summary><em> (2024) Onehousing Marketing Dashboard (Power BI)</em></summary> We built executive dashboard for high-level metrics (acqured users, MAU, lead funnel, etc.) of the OneHousing website, with detailed analytical views for specific marketing functions. I learnt how to work with Power BI.&nbsp;</details> <details style="padding-left: 40px;"> <summary><em> (2023) Onehousing Online-to-Offline Dashboard (Tableau)</em></summary> I built an operational dashboard to monitor detailed lead generation and conversion activities by salespeople.</details> <details style="padding-left: 40px;"> <summary><em> (2022) VinID Ticketing Dashboard (Superset)</em></summary> I built an operational dashboard about on-app ticket sales (concerts, football matches, recreational parks etc.) and conversion funnel.</details> <details style="padding-left: 40px;"> <summary><em>(2021) VinID OneView (web-based &amp; Looker Studio)<br/></em></summary> We built a centralized business intelligence platform, containing company-wise key metrics for C-level executives (MTU, MAU, etc.). I built 2 high-level dashboards in 2021: Merchant (about voucher metrics such as claims/redeems) and Product (about north-star app metrics) and I took over as sole maintainer of all related data pipelines in 2022 (200+ tables). I learnt how to debug and track down data errors in a complex pipelines.</details>]]></content><author><name></name></author><category term="work"/><category term="data-analytics,"/><category term="data-science,"/><category term="machine-learning"/><summary type="html"><![CDATA[A summary of what I did in my previous industry job as a Data Analyst]]></summary></entry><entry><title type="html">Quick Introduction to Federated Learning</title><link href="https://giangson19.github.io/blog/quick-introduction-to-federated-learning/" rel="alternate" type="text/html" title="Quick Introduction to Federated Learning"/><published>2025-04-05T00:00:00+00:00</published><updated>2025-04-05T00:00:00+00:00</updated><id>https://giangson19.github.io/blog/quick-introduction-to-federated-learning</id><content type="html" xml:base="https://giangson19.github.io/blog/quick-introduction-to-federated-learning/"><![CDATA[<table> <tbody> <tr> <td>Posted by Giang Son</td> <td>Apr 05, 2025</td> <td>5 min read A short technical introduction to federated learning, a framework for privacy preserving machine learning.In traditional machine learning, all the data is stored in one place and computation all happens on one computer (roughly speaking). The machine learning problem is formalized as minimizing a loss function with respect to the weights.And the loss function can be optimized using gradient descent. Each update is:The weights are updated iteratively until convergence or after a certain amount of times.As mentioned, to do centralized learning, all the data would need to be sent to one server for compute. This, of course, raises privacy concerns, especially if the training data contains some sensitive information about an user. For example, a keyboard suggestions model would need to collect data on what an user types.The solution proposed by Google (McMahan et al. 2016) is to distribute the data and the training. Continuing from the keyboard suggestion model, all the data would stay on the user’s phone, and the model training will happen on the device as well. They dubbed their method Federated Learning. Since its introduction by Google, some other big companies have used federated learning as well, including Apple, NVIDIA, and Amazon Web Services.The next parts will outline how to do federated learning.Federated learning is a procedure where training takes place locally so that there is no need to send data out of the local device. In this process, there will be a centralized server (say, the Google server), and there will be K clients (say K Android users).Learning takes place as follows:The process is repeated until convergence or after some predefined number of steps.As you can see, only the model weights are sent to the server, the data stays on the users’ phones.When the model is trained on a single device, we simply calculate the loss function for that client. And the loss function for the global model is the weighted average of all local losses (<em>). Intuitively, a client with more data points will contribute more towards the global loss.When performing gradient descent, the global weights is updated using the weighted average of the local gradients (gradients calculated on local data).This is done iteratively until… well you get the point.(</em>) This assumes that data across clients are i.i.d (independently and identically distributed). In practice, it is often the case some some client data are skewed (Zhao et al. 2018), which causes divergence problems. For possible remedy using FedProx, see Li et al. 2020.In the simple FedSGD algorithm, each gradient descent step will incur one round of transmission. Imagine training a model with 100 epochs, that means all clients will have to send (and receive) model weights 100 times. This is inefficient (and for that matter, increases privacy risks that I won’t elaborate here).To reduce the number of communication rounds, we can perform multiple gradient descent updates locally. And afterwards, we use a weighted average of all the local models as the new global model.Notice that with FedSGD, the local gradients are sent back to the server, whereas in FedAvg, the local weights (updated after several epochs) are sent instead. Moreover, the gradients are only transmitted after some number of epochs (as opposed to every epoch), thus reducing the number of communication rounds.While federated learning reduces privacy risks by keeping the data local while training the model instead of sending it to the server, it is still vulnerable to some other types of attack such as gradient inversion attack (Geiping et al. 2020) or membership inference attack. I will leave the of elaboration these risks as well as potential defenses to my future self as homework. (It literally is my homework, due in about 5 days).[1] McMahan, B., Moore, E., Ramage, D., Hampson, S. &amp; Arcas, B.A.y.. (2017). Communication-Efficient Learning of Deep Networks from Decentralized Data. Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, in Proceedings of Machine Learning Research 54:1273-1282[2] Geiping, J., Bauermeister, H., Dröge, H., &amp; Moeller, M. (2020). Inverting gradients-how easy is it to break privacy in federated learning?. Advances in neural information processing systems, 33, 16937-16947.[3] Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., &amp; Chandra, V. (2018). Federated learning with non-iid data. arXiv preprint arXiv:1806.00582. [4] Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., &amp; Smith, V. (2020). Federated optimization in heterogeneous networks. Proceedings of Machine learning and systems, 2, 429-450. [5] Federated Learning: Collaborative Machine Learning without Centralized Training Data  Thank you for reading. I’ve also written some other posts that you can check out. Copyright © 2023 Giang Son. Meticulously handcrafted with Django and Bootstrap.</td> </tr> </tbody> </table>]]></content><author><name></name></author><summary type="html"><![CDATA[A short technical introduction to federated learning, a framework for privacy preserving machine learning.]]></summary></entry><entry><title type="html">What’s it like to study in a Master’s?</title><link href="https://giangson19.github.io/blog/whats-it-like-to-study-in-a-masters/" rel="alternate" type="text/html" title="What’s it like to study in a Master’s?"/><published>2025-03-15T00:00:00+00:00</published><updated>2025-03-15T00:00:00+00:00</updated><id>https://giangson19.github.io/blog/whats-it-like-to-study-in-a-masters</id><content type="html" xml:base="https://giangson19.github.io/blog/whats-it-like-to-study-in-a-masters/"><![CDATA[<table> <tbody> <tr> <td>Posted by Giang Son</td> <td>Mar 15, 2025</td> <td>2 min read Quick notes on how studying in a Master’s differs from other levelsIn my humble experience, and roughly speaking.Sauce: The illustrated guide to a Ph.D.(*) which is why I think it is best to have some prior working experience before entering a Master’s. I believe you would gain a lot more compared to going in blind. Thank you for reading. I’ve also written some other posts that you can check out. Copyright © 2023 Giang Son. Meticulously handcrafted with Django and Bootstrap.</td> </tr> </tbody> </table>]]></content><author><name></name></author><summary type="html"><![CDATA[Quick notes on how studying in a Master's differs from other levels]]></summary></entry><entry><title type="html">My mentoring experience</title><link href="https://giangson19.github.io/blog/my-mentoring-experience/" rel="alternate" type="text/html" title="My mentoring experience"/><published>2025-03-01T00:00:00+00:00</published><updated>2025-03-01T00:00:00+00:00</updated><id>https://giangson19.github.io/blog/my-mentoring-experience</id><content type="html" xml:base="https://giangson19.github.io/blog/my-mentoring-experience/"><![CDATA[<p style="text-align: justify;">From Sep to Nov 2024, I was a <strong>Data Analytics Mentor</strong> (teaching assistant) at <strong>MindX Technology School</strong>. I mentored a group of 10 adult learners in Python, SQL and Power BI lessons. I expanded on concepts taught by the main teacher, guided students through technical exercises and provided them with practical advice on pursuing a career in data.&nbsp;</p> <p style="text-align: justify;">Between Dec 2022 and May 2024, I was a <strong>Data Analytics Mentor</strong> (internal trainer) at <strong>One Mount</strong>. I built a custom curriculum and taught a 5-lesson introductory SQL course for 30+ colleagues from the Marketing and Business Development department in Dec 2022. I gave practical advice on querying large datasets (billions of rows) and analytical methods specific to our business context.</p> <center><img src="https://media.licdn.com/dms/image/v2/D5622AQHiCYDSnAAw3Q/feedshare-shrink_800/feedshare-shrink_800/0/1717167494327?e=1748476800&amp;v=beta&amp;t=kwEyRJsasOTn7NBTStZfkjZhLauHeB_w26-bBSDy6jk" style="width:30%;"/></center> <p></p> <p style="text-align: justify;">Within my data analytics team of 10+ (our population varied over the years), I led multiple training sessions on technical skills relevant to our projects: applied machine learning, machine learning explanability, inferential statistics, dimensional data warehouse design (most of which I self-learnt). Ocasionally, I shared my knowledge about soft skills, namely critical thinking and problem solving.</p> <p style="text-align: justify;">From Mar to Nov 2019, I was an <strong>IELTS Tutor</strong> (teaching assistant) at <strong>LinhUK IELTS School</strong>. I assisted in classes of 4 IELTS skills, working mostly with high-school and university students. I graded writing assignments and provided detailed feedback on how to improve grammatical structure, lexical usage, and idea development. I also trained individually with numerous students in speaking exercise, giving practical advice on pronounciation, intonation and building reflexes to test questions.</p>]]></content><author><name></name></author><category term="work"/><category term="data-analytics,"/><category term="data-science,"/><category term="machine-learning"/><summary type="html"><![CDATA[Looking back at the times when I shared my knowledge]]></summary></entry></feed>